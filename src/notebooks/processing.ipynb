{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c110056",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../../config')\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807e2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d4e3a",
   "metadata": {},
   "source": [
    "## Tratamiento para contrarestar el desbalance de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cf148",
   "metadata": {},
   "source": [
    "### Modificar tamaño del dataset manteniendo relacion de 10:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f5d3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales: 284807\n",
      "Fraude: 492, No fraude original: 284315, No fraude usado: 4920\n",
      "Nuevo tamaño total: 5412\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(INITIAL_DATASET_ROUTE)\n",
    "\n",
    "# Suponemos que la columna de clase se llama \"Class\"\n",
    "# (ajusta este nombre según tu dataset)\n",
    "fraud_df = df[df[\"Class\"] == 1]\n",
    "no_fraud_df = df[df[\"Class\"] == 0]\n",
    "\n",
    "# Calcular la cantidad de fraudes y la cantidad deseada de no fraudes\n",
    "n_fraud = len(fraud_df)\n",
    "n_no_fraud = min(len(no_fraud_df), 10 * n_fraud)\n",
    "\n",
    "# Seleccionar aleatoriamente el subconjunto de \"No fraude\"\n",
    "no_fraud_subset = no_fraud_df.sample(n=n_no_fraud, random_state=42)\n",
    "\n",
    "# Unir ambos subconjuntos\n",
    "balanced_df = pd.concat([fraud_df, no_fraud_subset])\n",
    "\n",
    "# Mezclar las filas para evitar orden sesgado\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# Guardar el nuevo dataset balanceado\n",
    "\n",
    "print(f\"Datos originales: {len(df)}\")\n",
    "print(f\"Fraude: {n_fraud}, No fraude original: {len(no_fraud_df)}, No fraude usado: {n_no_fraud}\")\n",
    "print(f\"Nuevo tamaño total: {len(balanced_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a750352",
   "metadata": {},
   "source": [
    "### Manejar desbalance de clases y separar train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c9db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución original: {0: 4920, 1: 492}\n",
      "Train antes de SMOTE: {0: 3444, 1: 344}\n",
      "Train después SMOTE: {0: 3444, 1: 1722}\n",
      "Test (sin SMOTE):    {0: 1476, 1: 148}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ========= PARÁMETROS =========\n",
    "TEST_SIZE = 0.30\n",
    "SMOTE_RATIO = 0.5         # 1.0 = 1:1 ; 0.5 = 1 fraude por cada 2 no fraude\n",
    "# ==============================\n",
    "LABEL_COL = \"Class\"\n",
    "# 1) Cargar\n",
    "df = balanced_df\n",
    "\n",
    "# 2) Separar X e y (todo numérico)\n",
    "X = df.drop(columns=[LABEL_COL])\n",
    "y = df[LABEL_COL].astype(int)\n",
    "\n",
    "\n",
    "# 3) Split 70/30 estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "# 4) Escalado (fit SOLO en train)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# 5) SMOTE SOLO en train (ya escalado)\n",
    "smote = SMOTE(sampling_strategy=SMOTE_RATIO, random_state=SEED)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 6) Reconstruir DataFrames y guardar\n",
    "train_df = pd.DataFrame(X_train_sm, columns=X.columns)\n",
    "test_df  = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "train_df[LABEL_COL] = y_train_sm.values\n",
    "test_df[LABEL_COL]  = y_test.values\n",
    "\n",
    "train_df.to_csv(TRAIN_DATASET_ROUTE, index=False)\n",
    "test_df.to_csv(TEST_DATASET_ROUTE,  index=False)\n",
    "\n",
    "# 7) Reporte rápido\n",
    "def dist(yv):\n",
    "    vals, cnts = np.unique(yv, return_counts=True)\n",
    "    return {int(v): int(c) for v, c in zip(vals, cnts)}\n",
    "\n",
    "print(\"Distribución original:\", dist(y))\n",
    "print(\"Train antes de SMOTE:\", dist(y_train))\n",
    "print(\"Train después SMOTE:\", dist(y_train_sm))\n",
    "print(\"Test (sin SMOTE):   \", dist(y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
